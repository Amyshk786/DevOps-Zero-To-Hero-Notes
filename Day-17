Day 17 - Everything about Terraform |Write Your First Project |Remote Backend |Modules |Interview Q&A
======================================================================================================




This is the GitHub Repository which we can Follow for Todays Demo

Link - https://github.com/iam-veeramalla/write_your_first_terraform_project





As a User you Configure a Terraform Provider and Terraform Will Talk to the Target API what is a Target API  Let's say you have Provided Your Terraform Provider as AWS So What Terraform Will Understand Whatever the user has Written Like the Configuration Files, So Terraform Will Convert these Configuration Files Into the APIs that AWS will Understand and Tomorrow If You Want to Change your Entire Terraform Scripts into Azure Let's Say so what you will do is you will Modify the Script Files and Terraform Will do the Rest of the Things for you like you know you don't have to Worry About Of Course you have to Provide the Variables, Of course you have to Provide All the Required Information But the Templating Language is the Same. 



For Example If you Look at AWS Cloud Formation Templates Or Azure Resource Manager and If you want to Move from One Place to Another Place It's like you have to Learn Two Different Tools Now the options for the Cloud Providers is Vast Today you can use AWS, Tomorrow you might move to DIGITAL OCEAN Or you might move to a World of Hybrid Cloud like your Organization might have few things in AWS and few things in Azure. So instead if you just learn one terraform so terraform once you Provide the Provider Details it will Understand that so this is a provider let me convert the terraform configuration files into APIs that AWS would Understand Because AWS is Your Target So it will Convert your Configuration Files into Target AWS APIs and your terraform execution will take place.


So what you are Achieving with this you are Achieving like you know you can manage Any kind of Infrastructure tomorrow if there is a new Cloud that comes into Play let's say like Alibaba tomorrow you have something called as Xyz cloud so terraform or the Module Developers at Terraform like the Hashicorp or the Open Source Contributors they will take care of writing these APIs  all that you need to do is once they write the modules you have to write the Terraform Configuration files and like you know that's why you can Manage any kind of Infrastructure using Terraform Whether it is Existing clouds or whether it is the new clouds that are going to come in the future terraform will remain and will be the only tool that you have to learn.



Track your infrastructure that means to say with terraform like you don't have to log into your cloud provider and see what is the infrastructure that you have created let's say you have an organization that is created by terraform all the infrastructure what you can do is you can simply log into your terraform machine and you can look into the state file if your state file is stored in S3 buckets or any other places which is called as remote backends, You can just go to your S3 bucket and see how does your state file look like and it will explain your end entire AWS organization what are the resources that are created okay so that way you can keep a track of your infrastructure.



Automate changes what is automation of changes so with terraform you don't have to like you know uh let's say you have to make one simple change you don't have to manually log into a log into your infrastructure and make the changes instead you can automate and similarly you can collaborate as well like whenever you want to make any changes you can put this terraform files except your state file okay accept your state file you can put your terraform files in a git repository or any version control system and what you will do is using this version control system you can collaborate with your peers like if you are if you want to increase the let's say the resources of your ec2 instance instead of manually changing it you will go to git you will update your terraform file and you will ask one of your peers to review it so that they can review the code and they can say okay this is looking fine so that way you can automate changes with collaboration.




Standardized configuration standardized configuration means like there is a standard that you are maintaining with TF files right so like manually when you are doing things there is no standard with one cloud with one cloud provider you will do things in certain way and with another cloud provider you will do things in different way so instead what you are doing is you are standardizing the way that you are writing the configuration  so these are the advantages of terraform whenever somebody asks you why you want to move to terraform so these are the things that you have to communicate.






-----------------------------------------------------------------


Terraform Lifecycle -  [Write  ->  Dry Run  -> Apply]




# Terraform Commands 

terraform init

terraform plan

terraform apply	

terraform destroy




# It is a Good Practice to Have a Input.tf and Output.tf Files so that if anyone else wants to use our Terraform Files they can make the required Changes to input.tf or output.tf files.



-----------------------------------------------------------------



# Terraform Installation & Launching EC2 Instance Using Terraform
==================================================================



# You Can use the Below Mentioned Terraform Documentation on How to Install Terraform
Link - https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli



# GitHub Repo Used for this Video
Link - https://github.com/iam-veeramalla/write_your_first_terraform_project





# Once You have Installed Terraform Configure the AWS CLI 


# vim main.tf

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.16"
    }
  }

  required_version = ">= 1.2.0"
}

provider "aws" {
  region  = "us-east-1"
}

resource "aws_instance" "app_server" {
  ami           = "ami-005fc0f236362e99f"
  instance_type = "t2.micro"

  tags = {
    Name = "Terraform_Demo"
  }
}



# terraform init


# terraform plan


# terraform apply   [After Doing This A New Instance will be Created on AWS]






-----------------------------------------------------------------



# Terraform Advance Concepts
=============================


Note - 

In the Above case where we have Created a EC2 Instance Using Terraform The User will Have to Login to the AWS Console and Check if the Instance is Created or Not.


So to fix this we will Create a output.tf File and In that File we will Mention that we require These Information to be Shown to the User.


We can Also Create a Variable.tf file and We can Store All the variables in that file so the Values will not be Hard-Coded


Terraform maintains a state file (usually named terraform.tfstate) to keep track of resources created and their current state. The state is critical for determining what changes need to be applied during subsequent terraform apply operations. This state can also be stored remotely (e.g., in an S3 bucket) for shared environments or teams.




# Terraform State File Best Practices - 
========================================

1) You Should Store Your State Files Remotely (In Remote Backend), Not on Your Local Machine. 


2) It is Not a Good Idea to Store the State Files in Source Control like Git


3) Isolate and Organise the State Files to Reduce the Blast Radius [Eg as there are Multiple Env in Org like "Dev", "Staging", Unit-Testing, Pre-Production & Production so we must Isolate the Terraform State Files as it is a Good Practice]


4) Do Not Manipluate the State Files Locally






-----------------------------------------------------------------




# Terraform Remote Backend Concept - Always Store Your Terraform State File in Remote Backend Like Amazon S3 or Azure Storage Container
====================================


If Your Terraform State File is in a centralized locations like S3 what will happen is anybody who is trying to  modify or anybody who is executing your terraform scripts terraform will automatically update the state file in centralized location that is S3 bucket. And one more challenge that it is addresses is let's say there are two people who who is trying to execute this terraform scripts parallely so there are 100 people who are using this terraform scripts for example okay sometimes it can be even more and two users in this case there is only one user but let's say two users are trying to parallely run this terraform scripts so terraform should not allow that  if terraform allows that what will happen is let's say they are giving conflicting information to AWS so one is saying create a create  update the ec2 instance to two CPUs and other is saying update the ec2 instance to four CPUs and both of them are running parallel now what will terraform do which instruction will terraform take so to avoid that problem what you will do is that along with your remote backend you will integrate your remote backend with Dynamo DB. 


Here Dynamo DB is basically used for Locking the terraform State file what does it do it will lock your state file so once it is logged what terraform will say that state file is locked some other user is actually using the terraform scripts or some other user is performing infrastructure configuration on your AWS resources so wait until the configuration is done and once the S3 is free or once the resources in S3 are unlocked which is your state file is unlocked then you know I'll give you permissions to execute the terraform scripts so what is a good configuration or what is the ideal terraform configuration should look like always put your terraform configuration files or your TF files in GitHub or in any kind of Version Control System but your terraform State file should go into remote backends what is remote backends remote backends are nothing but your Remote Storage Services like it can be Amazon S3 bucket or it can be Azure Storage Container or something.


Store that in your Remote Back-End or Remote Storage Solutions and integrate them with proper Locking Solutions Like in the Above case of AWS the Locking Solution is Dynamo DB. What will happen is terraform will not allow parallel execution of terraform scripts so this is the ideal terraform setup that anyone should configure in their organization there is no chance of excuses here if you are even missing one of these things. 


You can replace Jenkins with Any other CI Solutions like GitHub Actions  or GitHub with any other VCS like GitLab or Bit-Bucket Stash

[If your Org is Not Using Jenkins or If they are not using GitHub for VCS in that case you can use the other alternate options]





-----------------------------------------------------------------



# Terraform Modules 
======================



A Terraform module is a way to group and reuse infrastructure resources across different environments or projects. A module in Terraform is essentially a container for multiple resources that are used together. Modules are a key concept that make infrastructure as code (IaC) more maintainable, scalable, and easier to organize.



1. Basic Concept of Modules


Root module: The root module is where your main configuration files are located. Every Terraform configuration has at least one module (the root module).


Child modules: A module called by another configuration is known as a child module. Child modules can be reused, nested, and combined in different ways.


Input and output variables: Modules use input variables to accept values from the root module (or other modules) and output variables to return values back.




------------------------------------------------



2. Why Use Terraform Modules?


Reusability: You can define infrastructure components once and use them multiple times across different environments or projects.


Consistency: By using a module, you ensure that the same infrastructure patterns are followed, reducing errors and increasing standardization.


Maintainability: Modules allow you to update a central template, which automatically propagates changes to wherever it’s used.


Encapsulation: They help break down a large Terraform configuration into smaller, manageable pieces.


Collaboration: Modules help teams share and collaborate on infrastructure code by abstracting away complex configurations into reusable components.




------------------------------------------------




3. Structure of a Module


A module is generally structured as follows:


Main file (main.tf): Contains the core logic and resource definitions.


Variables file (variables.tf): Declares input variables for the module.


Outputs file (outputs.tf): Specifies what values the module should output.


Optional files: You can also have other files like versions.tf (to specify Terraform versions), provider.tf (to declare providers), and locals.tf (for local values).




------------------------------------------------




4. Creating a Terraform Module

Here’s a basic example of how a Terraform module might look:

# variables.tf
variable "region" {
  description = "AWS region"
  type = string
}

# main.tf
provider "aws" {
  region = var.region
}

resource "aws_instance" "example" {
  ami = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
}

# outputs.tf
output "instance_id" {
  value = aws_instance.example.id
}

This module defines an AWS EC2 instance and accepts the AWS region as an input.



------------------------------------------------




5. Using Modules

You can use a module by calling it from another configuration (typically in the root module):

module "ec2_instance" {
  source = "./path_to_module"
  region = "us-west-2"
}

In this example:

source: Specifies the path to the module, which could be local or remote (from GitHub, Terraform Registry, etc.).

region: Input variable passed to the module.




------------------------------------------------



6. Module Sources

Modules can be sourced from:

Local paths: Using source = "./module_directory".

Terraform Registry: For example, source = "terraform-aws-modules/vpc/aws".

GitHub: You can specify a GitHub URL like source = "github.com/user/repo".

S3 buckets or HTTP URLs.




------------------------------------------------



7. Best Practices for Modules


Organize modules logically: Group resources by function (e.g., networking, compute) or by project.


Version control: Use versioning to maintain module stability and manage updates across environments.


Minimize complexity: Keep your modules small and focused on a single task to avoid overly complex configurations.


Documentation: Document your input variables, outputs, and usage to make the module easier to understand and reuse.




------------------------------------------------



8. Nested Modules

Modules can call other modules, allowing you to compose higher-level, complex modules by combining smaller, reusable ones:

module "networking" {
  source = "./modules/network"
  vpc_cidr = "10.0.0.0/16"
}

module "compute" {
  source = "./modules/compute"
  instance_type = "t2.micro"
  vpc_id = module.networking.vpc_id
}

In this scenario, the compute module relies on the output of the networking module (like the VPC ID).



------------------------------------------------



9. Remote State and Data Sources

Modules can access data from remote Terraform state files using terraform_remote_state or use external data sources with the data block:

data "terraform_remote_state" "vpc" {
  backend = "s3"
  config = {
    bucket = "my-bucket"
    key = "path/to/vpc.tfstate"
    region = "us-west-2"
  }
}

resource "aws_instance" "example" {
  ami = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
  subnet_id = data.terraform_remote_state.vpc.outputs.subnet_id
}



------------------------------------------------




10. Terraform Module Registry

Terraform has a public module registry where you can find pre-built modules for AWS, GCP, Azure, and other platforms. These modules can speed up your development process as they are often built and maintained by the community or cloud vendors.





---------------------------------------------------

# Conclusion - Terraform modules are a fundamental tool for organizing, sharing, and reusing your infrastructure as code configurations, making it easier to manage even the most complex infrastructure setups.











---------------------------------------------------


# Terraform Disadvantages
============================


- State File is a Single Source of Truth


- Manual Changes to the Cloud Provider Cannot be Identified and Auto-Corrected


- Not a GitOps Friendly Tool, Don't Play Well with FluxCD and ArgoCD


- Can become very Complex and Difficult to Manage


- Trying to Position as a Configuration Management Tool as Well

