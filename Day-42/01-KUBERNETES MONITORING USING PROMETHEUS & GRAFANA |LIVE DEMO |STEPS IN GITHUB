




DAY-42 | KUBERNETES MONITORING USING PROMETHEUS & GRAFANA |LIVE DEMO |STEPS IN GITHUB
=====================================================================================


# GitHub Repository Used - https://github.com/iam-veeramalla/observability-zero-to-hero/tree/main/day-2

# Docker Zero To Hero Repo Link - https://github.com/iam-veeramalla/Docker-Zero-to-Hero.git


# cd Docker-Zero-to-Hero/examples/python-web-app


Step 1: Update System Packages
- sudo apt-get update


Step 2: Install Required Packages
- sudo apt install -y curl wget apt-transport-https


Step 3: Install Docker
- sudo apt install -y docker.io -y


# Start and enable Docker.
- sudo systemctl enable --now docker


# Add current user to docker group (To use docker without root)
- sudo usermod -aG docker $USER && newgrp docker



Step 4: Install Minikube
- curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64


# Make it executable and move it into your path
- chmod +x minikube
sudo mv minikube /usr/local/bin/



Step 5: Install kubectl
- curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"


Check above image ⬆️ Make it executable and move it into your path
- chmod +x kubectl
sudo mv kubectl /usr/local/bin/



Step 6: Start Minikube
- minikube start --driver=docker --vm=true 



Step 7: Check Cluster Status
- minikube status


# You can also use kubectl to interact with your cluster
- kubectl get nodes




- kubectl get pods -A  [List the Pods in All the Namespaces]

NAMESPACE     NAME                               READY   STATUS    RESTARTS      AGE
kube-system   coredns-674b8bbfcf-6vzt5           1/1     Running   0             14m
kube-system   etcd-minikube                      1/1     Running   0             14m
kube-system   kube-apiserver-minikube            1/1     Running   0             14m
kube-system   kube-controller-manager-minikube   1/1     Running   0             14m
kube-system   kube-proxy-9ms5n                   1/1     Running   0             14m
kube-system   kube-scheduler-minikube            1/1     Running   0             14m
kube-system   storage-provisioner                1/1     Running   1 (14m ago)   14m




--------------------------------------------------------


# Prometheus Installation
==========================



- sudo snap install helm --classic

helm 3.18.6 from Snapcrafters✪ installed



- helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update




- helm install prometheus prometheus-community/prometheus 



- kubectl get pods

NAME                                                 READY   STATUS    RESTARTS   AGE
prometheus-alertmanager-0                            1/1     Running   0          2m11s
prometheus-kube-state-metrics-d4fd85895-48dk2        1/1     Running   0          2m12s
prometheus-prometheus-node-exporter-bcnz4            1/1     Running   0          2m12s
prometheus-prometheus-pushgateway-65ddfcc6c4-z9ccx   1/1     Running   0          2m11s
prometheus-server-776cc4757-b4jnc                    2/2     Running   0          2m12s





- kubectl get svc

NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kubernetes                            ClusterIP   10.96.0.1       <none>        443/TCP    25m
prometheus-alertmanager               ClusterIP   10.108.38.224   <none>        9093/TCP   4m19s
prometheus-alertmanager-headless      ClusterIP   None            <none>        9093/TCP   4m19s
prometheus-kube-state-metrics         ClusterIP   10.106.170.38   <none>        8080/TCP   4m19s
prometheus-prometheus-node-exporter   ClusterIP   10.103.35.171   <none>        9100/TCP   4m19s
prometheus-prometheus-pushgateway     ClusterIP   10.99.68.150    <none>        9091/TCP   4m19s
prometheus-server                     ClusterIP   10.108.13.110   <none>        80/TCP     4m19s





# We have Exposed the Service in NodePort Mode Earlier it was ClusterIP [U can see below a New server-ext has been created]

- kubectl expose service prometheus-server --type=NodePort --target-port=9090 --name=prometheus-server-ext

service/prometheus-server-ext exposed





- kubectl get svc

NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes                            ClusterIP   10.96.0.1       <none>        443/TCP        31m
prometheus-alertmanager               ClusterIP   10.108.38.224   <none>        9093/TCP       10m
prometheus-alertmanager-headless      ClusterIP   None            <none>        9093/TCP       10m
prometheus-kube-state-metrics         ClusterIP   10.106.170.38   <none>        8080/TCP       10m
prometheus-prometheus-node-exporter   ClusterIP   10.103.35.171   <none>        9100/TCP       10m
prometheus-prometheus-pushgateway     ClusterIP   10.99.68.150    <none>        9091/TCP       10m
prometheus-server                     ClusterIP   10.108.13.110   <none>        80/TCP         10m
prometheus-server-ext                 NodePort    10.103.149.58   <none>        80:30621/TCP   77s





- kubectl port-forward svc/prometheus-server-ext 31110:80 --address 0.0.0.0

We can Access Prometheus by Using http://PublicIP:31110 [As we have used EC2 so we have used Public IP]





--------------------------------------------------------


# Grafana Installation
====================== 


- helm repo add grafana https://grafana.github.io/helm-charts

"grafana" has been added to your repositories


- helm repo update



- helm install grafana grafana/grafana



1. By Default the Username for Grafana is "admin" and for getting the password  we have to run the below command

kubectl get secret --namespace default grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

oJu3LKng2nnonyJA3yjea7kjVrDZBSdkTpvm7DHI


2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster:

   grafana.default.svc.cluster.local




# Now if we will check the Grafana Svc is showing as Cluster IP so we will convert it to NodePort
- kubectl get svc
NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
grafana                               ClusterIP   10.111.23.187   <none>        80/TCP         3m24s
kubernetes                            ClusterIP   10.96.0.1       <none>        443/TCP        3h16m
prometheus-alertmanager               ClusterIP   10.108.38.224   <none>        9093/TCP       175m
prometheus-alertmanager-headless      ClusterIP   None            <none>        9093/TCP       175m
prometheus-kube-state-metrics         ClusterIP   10.106.170.38   <none>        8080/TCP       175m
prometheus-prometheus-node-exporter   ClusterIP   10.103.35.171   <none>        9100/TCP       175m
prometheus-prometheus-pushgateway     ClusterIP   10.99.68.150    <none>        9091/TCP       175m
prometheus-server                     ClusterIP   10.108.13.110   <none>        80/TCP         175m
prometheus-server-ext                 NodePort    10.103.149.58   <none>        80:30621/TCP   166m





- kubectl expose service grafana --type=NodePort --target-port=3000 --name=grafana-ext



- kubectl port-forward svc/grafana-ext 30200:80 --address 0.0.0.0


We can Access Grafana by Using http://PublicIP:30200 [As we have used EC2 so we have used Public IP]



# Once we LogIn into Grafana we have to Create a Data-Source so we will Click on Data Source & Provide URL of Prometheus  Save & Test


# Then we will Click on Dashboards and Enter "3662" So that Dashboard will be Imported

