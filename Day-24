Day-24 | Docker Zero to Hero Part-1 | Must Watch | Basics to Best Practices | Docker Commands
==============================================================================================



GitHub Repository Used in this Lecture 
Link - https://github.com/Amyshk786/Docker-Zero-to-Hero





A Virtual Machine that you have created on top of Hypervisor they have Complete Operating System or Full Operating System or the Guest Operating System because of which they are very heavy in nature like let's say an EC2 Instance whether you Use It or You don't use it you still have to pay money for your AWS or your cloud provider which you are Using.  On a Contrary Containers are very Lightweight in Nature that means on a specific virtual machine itself you can create multiple containers and if the containers are not running they don't use resources from the kernel what is a kernel kernel is part of your host operating system let's say you buy a Physical Infrastructure or you Create an EC2 Instance on AWS it basically has an operating system that has a Kernel so Kernel is Heart of your Operating System.



Now you Install Docker on Top of it and what Docker does is Whenever it Creates Containers it says that container you can use all the required resources from the Kernel but the Container Itself can have only Minimum System Dependencies now why this System Dependencies have to be there Because you know this container-1 and this container-2 have to be isolated like this can be container of project-1 and this can be container of project-2. 



If Container-1  is using All the Resources from the Kernel and Container-2 is also using All the Resources from the Kernel then that means to say that some hacker who is on Container-1 can Access the Application Locations or he can Technically get into Container-2 as well. So there has to be a Logical Isolation so containers even though they don't have complete operating system but they need to have some part of Logical Isolation without that Logical Isolation any people who can log into your Kubernetes Cluster any Hacker who can get into your Kubernetes Cluster or a Specific Container he can get into your all the Containers that are present on your cluster which is a dangerous hack or you are compromising with the security of your applications. So project-1  person should have logical isolation with Project-2  3 4 5 and 6 so that can be done by using some system dependencies and the rest of the things all of these containers can share from the kernel or the Host Operating System now what are these Files and Folders that Containers have inside them and what are the Resources that containers use from the Host Operating System.




# Files and Folders in containers base images:
===============================================


    /bin: contains binary executable files, such as the ls, cp, and ps commands.

    /sbin: contains system binary executable files, such as the init and shutdown commands.

    /etc: contains configuration files for various system services.

    /lib: contains library files that are used by the binary executables.

    /usr: contains user-related files and utilities, such as applications, libraries, and documentation.

    /var: contains variable data, such as log files, spool files, and temporary files.

    /root: is the home directory of the root user.






	

---------------------------------------------------



# Files and Folders that containers use from host operating system:
====================================================================


    The host's file system: Docker containers can access the host file system using bind mounts, which allow the container to read and write files in the host file system.
	

    Networking stack: The host's networking stack is used to provide network connectivity to the container. Docker containers can be connected to the host's network directly or through a virtual network.
	

    System calls: The host's kernel handles system calls from the container, which is how the container accesses the host's resources, such as CPU, memory, and I/O.
	

    Namespaces: Docker containers use Linux namespaces to create isolated environments for the container's processes. Namespaces provide isolation for resources such as the file system, process ID, and network.
	

    Control groups (cgroups): Docker containers use cgroups to limit and control the amount of resources, such as CPU, memory, and I/O, that a container can access.
    







---------------------------------------------------


So Instead of Running 1 Virtual Machine what you can do is you can run 10 to 20 or 30 to 40 containers on the same virtual machine right depending on how much resources your Containers are using from the host operating system so there are cases where if your containers are using a lot of resources from your host operating system or you can predefine your containers with resources like saying that my container has to definitely start with 256 MB so in such cases this is not applicable but by default the beauty of the containers is if they are not running then they will allow other containers to use the resources from the kernel or host operating system so that's why you can run n number of containers depending on how much your containers are using from the operating system. 



So what is blocking the same thing on Virtual machines because your virtual machines have individual guest operating system so this kernel all the resources that are used by the kernel will not allow other virtual machine to use resources from like application 2 in Virtual Machine 2 cannot use the kernel related resources from virtual machine 1.






---------------------------------------------------


# Docker 


Docker is a containerization platform that provides easy way to containerize your applications, which means, using Docker you can build container images, run the images to create containers and also push these containers to container regestries such as DockerHub, Quay.io and so on.

In simple words, you can understand as containerization is a concept or technology and Docker Implements Containerization.





You use this Docker CLI to Execute the Some Docker Commands which are received by the docker Daemon and Docker Daemon ensures to create your requirement if you are asking Docker build then Docker demon will build a Docker image for you if you use the docker client to execute a command called as Docker run then it will create a container for you if you are using the docker client to execute a command called Docker pull then Docker demon will receive this command and it will basically pull the containers from your registry it can be private or it can public now how does Docker demon understand uh what is your registry where are these images stored or where I have to push this firstly you have to create a account with Docker Hub and you need to Log-In to it.




---------------------------------------------------

# Docker LifeCycle
==================


We can use the above Image as reference to understand the lifecycle of Docker. There are three important things,


docker build -> builds docker images from Dockerfile

docker run -> runs container from docker images

docker push -> push the container image to public/private regestries to share the docker images.







---------------------------------------------------




Understanding the terminology (Inspired from Docker Docs)


1) Docker daemon
The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.





2) Docker client
The Docker client (docker) is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. The docker command uses the Docker API. The Docker client can communicate with more than one daemon.





3) Docker Desktop
Docker Desktop is an easy-to-install application for your Mac, Windows or Linux environment that enables you to build and share containerized applications and microservices. Docker Desktop includes the Docker daemon (dockerd), the Docker client (docker), Docker Compose, Docker Content Trust, Kubernetes, and Credential Helper. For more information, see Docker Desktop.





4) Docker registries
A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use, and Docker is configured to look for images on Docker Hub by default. You can even run your own private registry.

When you use the docker pull or docker run commands, the required images are pulled from your configured registry. When you use the docker push command, your image is pushed to your configured registry. Docker objects

When you use Docker, you are creating and using images, containers, networks, volumes, plugins, and other objects. This section is a brief overview of some of those objects.





5) Dockerfile
Dockerfile is a file where you provide the steps to build your Docker Image.





6) Images
An image is a read-only template with instructions for creating a Docker container. Often, an image is based on another image, with some additional customization. For example, you may build an image which is based on the ubuntu image, but installs the Apache web server and your application, as well as the configuration details needed to make your application run.

You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.






---------------------------------------------------


# Practical 



- This is the Dockerfile Which we have Used for the Practical 

#######################################

# We are Getting the Ubuntu Base Image from Docker-Hub
FROM ubuntu:latest    

# Set the working directory in the image
WORKDIR /app

# Copy the files from the host file system to the image file system
COPY . /app

# Install the necessary packages
RUN apt-get update && apt-get install -y python3 python3-pip

# Set environment variables
ENV NAME World

# Run a command to start the application
CMD ["python3", "app.py"]


#######################################


# Update the Packages
sudo apt update


# Install Docker
sudo apt install docker.io -y



# Grant Access to your user to run docker commands
sudo usermod -aG docker ubuntu



# Start Docker daemon
sudo systemctl start docker



# Check Status of Docker daemon
sudo systemctl status docker




# A easy way to verify your Docker installation is by running the below command
docker run hello-world

# Output = 

....
....
Hello from Docker!
This message shows that your installation appears to be working correctly.
...
...




# Clone this repository and move to example folder 
git clone https://github.com/iam-veeramalla/Docker-Zero-to-Hero

ls 

cd Docker-Zero-to-Hero 


cd examples


ls 

cd first-docker-file



# Login to Docker 
docker login




# Build your first Docker Image
docker build -t amyshaikh623/my-first-docker-image:latest .




# Verify Docker Image is created
docker images 

Output = docker images
REPOSITORY                            TAG       IMAGE ID       CREATED          SIZE
amyshaikh623/my-second-docker-image   latest    76deb49ab677   10 minutes ago   562MB
amyshaikh623/my-first-docker-image    latest    8aff5f6282e9   14 minutes ago   562MB
ubuntu                                latest    dc4c1391d370   5 days ago       78.1MB
hello-world                           latest    d2c94e258dcb   17 months ago    13.3kB







# Run your First Docker Container
docker run -it amyshaikh623/my-first-docker-image

Output = docker run -it amyshaikh623/my-first-docker-image
Hello World





# Push the Image to DockerHub and share it with the world
docker push amyshaikh623/my-first-docker-image:latest 




Note - Now The Image will be Pushed to the Docker Hub and If Anyone in the World wants to Use that Image they can use the below Command

docker pull amyshaikh623/my-first-docker-image:latest










---------------------------------------------------


# Docker Commands
==================

Some of the most commonly used docker commands are listed below:


### docker images

Lists docker images on the host machine.





### docker build

Builds image from Dockerfile.





### docker run

Runs a Docker container. 

There are many arguments which you can pass to this command for example,

`docker run -d` -> Run container in background and print container ID
`docker run -p` -> Port mapping

use `docker run --help` to look into more arguments.





### docker ps

Lists running containers on the host machine.





### docker stop

Stops running container.





### docker start

Starts a stopped container.





### docker rm

Removes a stopped container.





### docker rmi

Removes an image from the host machine.





### docker pull

Downloads an image from the configured registry.





### docker push

Uploads an image to the configured registry.





### docker exec

Run a command in a running container.





### docker network

Manage Docker networks such as creating and removing networks, and connecting containers to networks.


